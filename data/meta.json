{
    "nodes": [
        {
            "id": "Token Classification",
            "type": "token-classification",
            "desc": "Token classification is a natural language understanding task in which a label is assigned to some tokens in a text. Some popular token classification subtasks are Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. NER models could be trained to identify specific entities in a text, such as dates, individuals and places; and PoS tagging would identify, for example, which words in a text are verbs, nouns, and punctuation marks.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The token to classify."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "ARRAY",
                    "items": {
                        "type": "JSON",
                        "properties": {
                            "word": "STRING",
                            "entity_group": "STRING"
                        }
                    },
                    "description": "The predicted class of the token."
                }
            ]
        },
        {
            "id": "Text Classification",
            "type": "text-classification",
            "desc": "Text classification is the task of classifying text into one or more categories.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The text to classify."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "STRING",
                    "description": "The human-readable predicted class of the text. Eg: 'happy', v.v"
                }
            ]
        },
        {
            "id": "Zero-Shot Classification",
            "type": "zero-shot-classification",
            "desc": "Zero-Shot Classification is the task of classifying text into one or more categories, without being trained on any of the categories.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The text to classify."
                },
                {
                    "name": "labels",
                    "type": "ARRAY",
                    "items": {
                        "type": "STRING"
                    },
                    "description": "The labels want to be classified the text into."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "STRING",
                    "description": "The human-readable predicted class of the text. Eg: 'happy', v.v"
                }
            ]
        },
        {
            "id": "Translation",
            "type": "translation",
            "desc": "Translation is the task of converting text from one language to another.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The text to translate."
                }
            ],
            "outputs": [
                {
                    "name": "translation_text",
                    "type": "STRING",
                    "description": "The translated text."
                }
            ],
            "examples": [
                {
                    "description": "",
                    "example": {
                        "input": "",
                        "output": ""
                    }
                }
            ]
        },
        {
            "id": "Summarization",
            "type": "summarization",
            "desc": "Summarization is the task of producing a shorter version of a document while preserving its important information. Some models can extract text from the original input, while other models can generate entirely new text.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "file",
                    "type": "STRING",
                    "description": "If don't have text, you can use file to summarize."
                },
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "If don't have file, you can use text to summarize."
                }
            ],
            "outputs": [
                {
                    "name": "summary_text",
                    "type": "STRING",
                    "description": "The summary of the text."
                }
            ]
        },
        {
            "id": "Question Answering",
            "type": "question-answering",
            "desc": "Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document.",
            "input-type": [
                "text",
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The question to answer."
                },
                {
                    "name": "context",
                    "type": "STRING",
                    "description": "The context to answer the question from."
                }
            ],
            "outputs": [
                {
                    "name": "answer",
                    "type": "STRING",
                    "description": "The answer to the question."
                }
            ]
        },
        {
            "id": "Conversational",
            "type": "conversational",
            "desc": "Conversational response modelling is the task of generating conversational text that is relevant, coherent and knowledgable given a prompt. These models have applications in chatbots, and as a part of voice assistants",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ]
        },
        {
            "id": "Text Generation",
            "type": "text-generation",
            "desc": "Generating text is the task of producing new text. These models can, for example, fill in incomplete text or paraphrase.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The query to generate text from."
                }
            ],
            "outputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The generated text."
                }
            ]
        },
        {
            "id": "Sentence Similarity",
            "type": "sentence-similarity",
            "desc": "Sentence Similarity is the task of determining how similar two texts are. This task is particularly useful for information retrieval and clustering/grouping.",
            "input-type": [
                "text",
                "text"
            ],
            "output-type": [],
            "inputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The sentence to compare."
                },
                {
                    "name": "other_sentences",
                    "type": "ARRAY",
                    "items": {
                        "type": "STRING"
                    },
                    "description": "The other sentences to compare."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "ARRAY",
                    "items": {
                        "type": "NUMBER"
                    },
                    "description": "The sequence of similarity score of the sentence."
                }
            ]
        },
        {
            "id": "Tabular Classification",
            "type": "tabular-classification",
            "desc": "Tabular classification is the task of classifying a table (in Image format).",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "row",
                    "type": "JSON",
                    "description": "A row of the table."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "STRING",
                    "description": "The predicted class of the row."
                }
            ]
        },
        {
            "id": "Object Detection",
            "type": "object-detection",
            "desc": "Object Detection models allow users to identify objects of certain defined classes. Object detection models receive an image as input and output the images with bounding boxes and labels on detected objects.",
            "input-type": [
                "image"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "image",
                    "type": "STRING",
                    "description": "The path to the image file."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "ARRAY",
                    "items": {
                        "type": "JSON",
                        "properties": {
                            "box": {
                                "type": "JSON",
                                "properties": {
                                    "xmin": "NUMBER",
                                    "ymin": "NUMBER",
                                    "xmax": "NUMBER",
                                    "ymax": "NUMBER"
                                }
                            },
                            "label": "STRING",
                            "score": "NUMBER"
                        }
                    },
                    "description": "The predicted class of the image."
                }
            ]
        },
        {
            "id": "Image Classification",
            "type": "image-classification",
            "desc": "Image classification is the task of assigning a label or class to an entire image. Images are expected to have only one class for each image. Image classification models take an image as input and return a prediction about which class the image belongs to.",
            "input-type": [
                "image"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "image",
                    "type": "BASE64|PIL.Image|Path|numpy.ndarray|torch.Tensor",
                    "description": "The image is a string, PIL.Image or path to the image file, numpy.ndarray or torch.Tensor."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "STRING",
                    "description": "The special predicted class of the image. Eg: digital watch, muzzle, v.v"
                }
            ]
        },
        {
            "id": "Image-to-Image",
            "type": "image-to-image",
            "desc": "Image-to-image is the task of transforming a source image to match the characteristics of a target image or a target image domain. Any image manipulation and enhancement is possible with image to image models.",
            "input-type": [
                "image"
            ],
            "output-type": [
                "image"
            ],
            "inputs": [

            ],
            "outputs": [

            ]
        },
        {
            "id": "Image-to-Text",
            "type": "image-to-text",
            "desc": "Image to text models output a text from a given image. Image captioning or optical character recognition can be considered as the most common applications of image to text.",
            "input-type": [
                "image"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "image",
                    "type": "BASE64|PIL.Image|Path|numpy.ndarray|torch.Tensor",
                    "description": "The image is a string, PIL.Image or path to the image file, numpy.ndarray or torch.Tensor."
                }
            ],
            "outputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The text from the image."
                }
            ]
        },
        {
            "id": "Text-to-Image",
            "type": "text-to-image",
            "desc": "Generates images from input text. These models can be used to generate images based on text prompts.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "image"
            ]
        },
        {
            "id": "Text-to-Video",
            "type": "text-to-video",
            "desc": "Generates videos from input text. These models can be used to generate videos based on text prompts.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "video"
            ]
        },
        {
            "id": "Visual Question Answering",
            "type": "visual-question-answering",
            "desc": "Visual Question Answering is the task of answering questions based on an image.",
            "input-type": [
                "image",
                "text"
            ],
            "output-type": [
                "text"
            ]
        },
        {
            "id": "Document Question Answering",
            "type": "document-question-answering",
            "desc": "Document Question Answering (also known as Document Visual Question Answering) is the task of answering questions on document images. Document question answering models take a (document, question) pair as input and return an answer in natural language. Models usually rely on multi-modal features, combining text, position of words (bounding-boxes) and image.",
            "input-type": [
                "image",
                "text"
            ],
            "output-type": [
                "text"
            ]
        },
        {
            "id": "Image Segmentation",
            "type": "image-segmentation",
            "desc": "Image Segmentation divides an image into segments where each pixel in the image is mapped to an object. This task has multiple variants such as instance segmentation, panoptic segmentation and semantic segmentation.",
            "input-type": [
                "image"
            ],
            "output-type": [
                "image"
            ]
        },
        {
            "id": "Depth Estimation",
            "type": "depth-estimation",
            "desc": "Depth estimation is the task of predicting depth of the objects present in an image.",
            "input-type": [
                "image"
            ],
            "output-type": [
                "image"
            ]
        },
        {
            "id": "Text-to-Speech",
            "type": "text-to-speech",
            "desc": "Text-to-Speech (TTS) is the task of generating natural sounding speech given text input. TTS models can be extended to have a single model that generates speech for multiple speakers and multiple languages.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "audio"
            ]
        },
        {
            "id": "Automatic Speech Recognition",
            "type": "automatic-speech-recognition",
            "desc": "Automatic Speech Recognition (ASR), also known as Speech to Text (STT), is the task of transcribing a given audio to text. It has many applications, such as voice user interfaces.",
            "input-type": [
                "audio"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "audio",
                    "type": "STRING|BASE64|bytes",
                    "description": "The path to the audio file or the audio file in base64 format or the bytes of audio file."
                }
            ],
            "outputs": [
                {
                    "name": "text",
                    "type": "STRING",
                    "description": "The transcribed text."
                }
            ]
        },
        {
            "id": "Audio-to-Audio",
            "type": "audio-to-audio",
            "desc": "Audio-to-Audio is a family of tasks in which the input is an audio and the output is one or multiple generated audios. Some example tasks are speech enhancement and source separation.",
            "input-type": [
                "audio"
            ],
            "output-type": [
                "audio"
            ]
        },
        {
            "id": "Audio Classification",
            "type": "audio-classification",
            "desc": "Audio classification is the task of assigning a label or class to a given audio. It can be used for recognizing which command a user is giving or the emotion of a statement, as well as identifying a speaker.",
            "input-type": [
                "audio"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "audio",
                    "type": "STRING|BASE64|bytes",
                    "description": "The path to the audio file or the audio file in base64 format or the bytes of audio file."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "STRING",
                    "description": "The predicted class of the audio."
                }
            ]
        },
        {
            "id": "Image Editing",
            "type": "image-editing",
            "desc": "Image editing is the task of modifying an image to match a given text description. It can be used to modify the attributes of an image, such as the color of an object or the background.",
            "input-type": [
                "text"
            ],
            "output-type": [
                "image"
            ]
        },
        {
            "id": "Tabular Regression",
            "type": "tabular-regression",
            "desc": "Tabular regression is the task of predicting a continuous value from a given table (in Image format).",
            "input-type": [
                "text"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "row",
                    "type": "JSON",
                    "description": "A row of the table."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "NUMBER",
                    "description": "The predicted value of the row."
                }
            ]
        },
        {
            "id": "Video Classification",
            "type": "video-classification",
            "desc": "Video classification is the task of classifying a video into one or more classes.",
            "input-type": [
                "video"
            ],
            "output-type": [
                "text"
            ],
            "inputs": [
                {
                    "name": "video",
                    "type": "Path",
                    "description": "The path to the video file."
                }
            ],
            "outputs": [
                {
                    "name": "predicted",
                    "type": "STRING",
                    "description": "The predicted class of the video."
                }
            ]
        }
    ]
}